{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e62a0e",
   "metadata": {},
   "source": [
    "Poppy humanoid robot is a humanoid robot that can be used with its hardware platform or with the CoppeliaSim simulator. It can be programmed with python, using the pypot library.\n",
    "\n",
    "Download and install the simulator CoppeliaSim from https://www.coppeliarobotics.com/downloads "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d7746",
   "metadata": {},
   "source": [
    "# Setup the software\n",
    "\n",
    "Poppy uses pypot for control. It is a python library : http://poppy-project.github.io/pypot/. \n",
    "On the top of pypot are libraries for Poppy creatures : https://github.com/poppy-project.\n",
    "The quick install consists in:\n",
    "- install pypot :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38894b80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install pypot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189f627",
   "metadata": {},
   "source": [
    "- install your poppy creature with its geometry :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install poppy_torso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08251879",
   "metadata": {},
   "source": [
    "- install the library **ikpy** that proposes the inverse kinematics of the robot. The source code is https://github.com/Phylliade/ikpy. See tutorial on https://notebook.community/Phylliade/ikpy/tutorials/Moving%20the%20Poppy%20Torso%20using%20Inverse%20Kinematics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df445384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install 'ikpy[plot]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4c7cf",
   "metadata": {},
   "source": [
    "We use another algorithm for human pose estimation : Blazepose :\n",
    "- the article describing the algorithm is in https://arxiv.org/abs/2006.10204\n",
    "- the source code is still available at https://github.com/google/mediapipe\n",
    "\n",
    "To install, use the command : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d213243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d3ef68",
   "metadata": {},
   "source": [
    "# Start your code\n",
    "Now you are done with the installation phase. You can start your project by importing the different libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94a4033",
   "metadata": {},
   "source": [
    "## Capture a video with a camera\n",
    "\n",
    "For this section only, you need to install first opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f98919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "#time.sleep(5)\n",
    "\n",
    "# Open a connection to the cameras\n",
    "# cap1 = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0985282",
   "metadata": {},
   "source": [
    "Capture the frames of the camera for 10 seconds. Save as file cam1.avi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ab6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_width_1 = int(cap1.get(3))\n",
    "# frame_height_1 = int(cap1.get(4))\n",
    "# # if you want to change the resolution of the camera\n",
    "# #cap1.set(3,frame_width_1)\n",
    "# #cap1.set(4,frame_height_1)\n",
    "\n",
    "   \n",
    "# size_1 = (frame_width_1, frame_height_1)\n",
    "\n",
    "# video_nom_1 = \"cam1.avi\"\n",
    "\n",
    "# # Compression\n",
    "# lossless = cv2.VideoWriter_fourcc(* 'FFV1')\n",
    "\n",
    "# # Save the frame as an video file\n",
    "# video_1 = cv2.VideoWriter(video_nom_1, lossless, 30, size_1)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "# while  time.time() < start + 10:\n",
    "\n",
    "#     # Capture a frame from the cameras\n",
    "#     ret1, frame1 = cap1.read()\n",
    "\n",
    "#     # Check if the user pressed the enter key\n",
    "#     cv2.waitKey(1)\n",
    "\n",
    "#     if ret1:\n",
    "#         #cv2.imshow(\"Webcam 1\", frame1) #to display the camera images\n",
    "#         video_1.write(frame1)\n",
    "    \n",
    "\n",
    "# video_1.release()\n",
    "            \n",
    "# # Release the camera and close the window\n",
    "# cap1.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c18aa",
   "metadata": {},
   "source": [
    "# Instantiate the robot\n",
    "\n",
    "Now open the simulator CoppeliaSim. Click yes when prompted if you accept all incoming communications.\n",
    "For MacOs, type in the Sandbox script terminal\n",
    "\n",
    "simExtRemoteApiStart(19997)\n",
    "\n",
    "If instead it does now appear and you get an error message like\n",
    "\n",
    "\n",
    "> pypot.vrep.io.VrepConnectionError: Could not connect to V-REP server on 127.0.0.1:19997. This could also means that you still have a previously opened connection running! (try pypot.vrep.close_all_connections())\n",
    ">\n",
    "> During handling of the above exception, another exception occurred:\n",
    ">\n",
    "> pypot.vrep.io.VrepIOErrors: No value\n",
    "\n",
    "type in the Sandbox script terminal\n",
    "\n",
    "simExtRemoteApiStart(19997)\n",
    "    \n",
    "\n",
    "Instantiate the poppy robot in the simulator with the code below, this is necessary in order to add the kinematic chains attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7db6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypot import vrep\n",
    "vrep.close_all_connections()\n",
    "poppy = PoppyTorso(simulator='vrep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a8627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in poppy.motors:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f0ca28",
   "metadata": {},
   "source": [
    "Poppy should now appear on the CoppeliaSim simulation screen, and a popup appeared in CoppeliaSim to inform you that the simulation use custom parameters. This popup block the communication to the Python API of CoppeliaSim. You have to check the check-box “Do not show this message again” and press “Ok”. Do this 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea7065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = None\n",
    "targets = None\n",
    "smoothed_targets = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f94a45",
   "metadata": {},
   "source": [
    "For each kinematic chain we have built an urdf file. We create an IKChain object for each kinematic chain, making it possible to compute the inverse kinematics, i.e. motor angles from desired end-effector position.\n",
    "\n",
    "The constructor takes as input the poppy robot instance, the motors that are part of the kinematic chain, the motors that remain passive during the inverse kinematics, the distance of the tip of the last bone of the chain, and finally, the list of motors for which the urdf file give reversed orientation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605a3ec",
   "metadata": {},
   "source": [
    "We can plot some of these kinematic chains in a figure. If the position of the robot in the simulator is changed, these changes should be reflected when reexecuting this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96bd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "zero = [0] * 7\n",
    "\n",
    "ax = matplotlib.pyplot.figure().add_subplot(111, projection='3d')\n",
    "ax.scatter([0], [0],[0])\n",
    "\n",
    "poppy.l_arm_chain.plot(poppy.l_arm_chain.convert_to_ik_angles(poppy.l_arm_chain.joints_position), ax, target = (0.2, -0.2, 0.2))\n",
    "poppy.r_arm_chain.plot(poppy.r_arm_chain.convert_to_ik_angles(poppy.r_arm_chain.joints_position), ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77950c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae3c7c8",
   "metadata": {},
   "source": [
    "The robot is now ready to use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c58fd",
   "metadata": {},
   "source": [
    "# Using the robot Poppy\n",
    "\n",
    "\n",
    "\n",
    "You can directly access the chains:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de32f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"chaine  \" , poppy.l_arm_chain)\n",
    "print(\"nom     \" , poppy.l_arm_chain.name)\n",
    "print(\"links   \" , poppy.l_arm_chain.links)\n",
    "print(\"1er link\" , poppy.l_arm_chain.links[1].name)\n",
    "#print(poppy.torso_chain)\n",
    "#print(poppy.l_elbow_chain   )\n",
    "#print(poppy.l_elbow_chain   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3f9d0",
   "metadata": {},
   "source": [
    "You can access their respective motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m.name for m in poppy.l_arm_chain.motors]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770ec8f0",
   "metadata": {},
   "source": [
    "You can access the state of the robot.\n",
    "\n",
    "joints_position returns the joint angles for all the motors of the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb758c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poppy.l_arm_chain.joints_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d25452",
   "metadata": {},
   "source": [
    "position returns the cartesian position of the end effector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1fb74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poppy.l_arm_chain.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2455079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppy.l_shoulder_y.goto_position(-30,3)\n",
    "poppy.l_shoulder_x.goto_position(30,3)\n",
    "poppy.abs_z.goto_position(-20,3)\n",
    "print(poppy.l_arm_chain.position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d0fe6",
   "metadata": {},
   "source": [
    "Reset the robot to an initial position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ed3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poppy_reset():\n",
    "    joint_pos = { 'l_elbow_y':0.0,\n",
    "                 'head_y': 0.0,\n",
    "                 'r_arm_z': 0.0, \n",
    "                 'head_z': 0.0,\n",
    "                 'r_shoulder_x': 0.0, \n",
    "                 'r_shoulder_y': 0.0,\n",
    "                 'r_elbow_y': 0.0, \n",
    "                 'l_arm_z': 0.0,\n",
    "                 'abs_z': 0.0,\n",
    "                 'bust_y': 0.0, \n",
    "                 'bust_x':0.0,\n",
    "                 'l_shoulder_x': 0.0,\n",
    "                 'l_shoulder_y': 0.0\n",
    "                }\n",
    "    for m in poppy.motors:\n",
    "        m.goto_position(joint_pos[m.name],5)\n",
    "\n",
    "poppy_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebbebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poppy.abs_z.goto_position(-180,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0adfe13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pypot.primitive.move import Move\n",
    "fps =10\n",
    "\n",
    "move = Move(freq=fps)\n",
    " \n",
    "\n",
    "print(\"list of all motors of poppy\", [m.name for m in poppy.motors])\n",
    "move_motors = [m.name for m in poppy.motors]\n",
    "\n",
    "\n",
    "for t in np.linspace(0.02,3,int(3*fps)):\n",
    "        new_positions = {}\n",
    "        for motor in move_motors:\n",
    "            # decide for each timestep and each motor a joint angle and a velocity\n",
    "            new_positions[motor] = [20*np.sin(t), 0.0]\n",
    "\n",
    "        move.add_position(new_positions, t)\n",
    "        \n",
    "#print(\"joint positions of the move \",(move._timed_positions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f17ab4",
   "metadata": {},
   "source": [
    "Before sending the motor commands to the robot, reset the robot to an initial position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaf51cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppy_reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef7fa1a",
   "metadata": {},
   "source": [
    "Send the motor commands to the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MovePlayer(poppy, move,play_speed=1)\n",
    "mp.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c051f1",
   "metadata": {},
   "source": [
    "Record the movement in an file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "move.save(open('new_movement.record', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d242c3d",
   "metadata": {},
   "source": [
    "# Imitation by inverse kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00343adc",
   "metadata": {},
   "source": [
    "This function is a wrapper for the inverse kinematics methods of the IKChain objects.\n",
    "\n",
    "If no initial position is provided, the method will use the current position of the robot in the simulator, and will automatically control the simulated robot towards the provided target.\n",
    "\n",
    "It returns the new joints angle coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ik(kinematic_chain, target_position, initial_position=None):\n",
    "    \n",
    "    kwargs = {}\n",
    "    kwargs['max_iter'] = 3\n",
    "    if initial_position is not None:\n",
    "        kwargs['initial_position'] = kinematic_chain.convert_to_ik_angles(initial_position)\n",
    "    else:\n",
    "        kwargs['initial_position'] = kinematic_chain.convert_to_ik_angles(kinematic_chain.joints_position)\n",
    "\n",
    "    q = kinematic_chain.inverse_kinematics(\n",
    "        target_position=target_position,\n",
    "        orientation_mode=None,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    joints = kinematic_chain.convert_from_ik_angles(q)\n",
    "\n",
    "    last = kinematic_chain.motors[-1]\n",
    "    \n",
    "    if initial_position is None:\n",
    "        for i, (m, pos) in enumerate(list(zip(kinematic_chain.motors, joints))):\n",
    "            if kinematic_chain.active_links_mask[i+1]:\n",
    "                m.goal_position = pos\n",
    "        \n",
    "    return joints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084607c4",
   "metadata": {},
   "source": [
    "## Pose estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7e078c",
   "metadata": {},
   "source": [
    "This function uses blazepose to compute the skeleton based on a video file.\n",
    "Blazepose/Mediapipe is a 3D human pose estimation algorithm that can run in realtime on a CPU computer. \n",
    "\n",
    "This function processes a video and returns a list of positions (x,y,z) for each joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339289b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "skeletons = blazepose_skeletons('mai1.mov')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2a3a0a",
   "metadata": {},
   "source": [
    "Let's examine the skeletons variable. It is a tensor of size :\n",
    "- the number of frames in the video\n",
    "- 17 joints in the human figure model\n",
    "- 3 for the (x,y,z) positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e84378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(skeletons.shape)\n",
    "print(skeletons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67026fd6",
   "metadata": {},
   "source": [
    "Normalize the skeleton, change the reference frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165744af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_frame(skeletons, frame_name, alpha, topology):\n",
    "\n",
    "    rota_skeletons_A = skeletons.clone()\n",
    "    rota_skeletons_A[:, :, 2] = -skeletons[:, :, 1]\n",
    "    rota_skeletons_A[:, :, 1] = skeletons[:, :, 2]\n",
    "    center_A = rota_skeletons_A[:, 0,:].unsqueeze(1).repeat(1, len(topology), 1)\n",
    "    rota_skeletons_A = rota_skeletons_A - center_A\n",
    "\n",
    "    batch_size, n_joints, _ = rota_skeletons_A.shape\n",
    "        \n",
    "\n",
    "    # Measure skeleton bone lengths\n",
    "    lengths = torch.Tensor(batch_size, n_joints)\n",
    "    for child, parent in enumerate(topology):\n",
    "            lengths[:, child] = torch.sqrt(\n",
    "                torch.sum(\n",
    "                    (rota_skeletons_A[:, child] - rota_skeletons_A[:, parent])**2,\n",
    "                    axis=-1\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Find the corresponding angles\n",
    "    offsets = torch.zeros(batch_size, n_joints, 3)\n",
    "    offsets[:, :, -1] = lengths\n",
    "    quaternions = find_quaternions(topology, offsets, rota_skeletons_A)\n",
    "        \n",
    "    # Rotate of alpha\n",
    "    #define the rotation by its quaternion \n",
    "    rotation = torch.Tensor([np.cos(alpha/2),  np.sin(alpha/2),0,0]).unsqueeze(0).repeat(batch_size*n_joints, 1)\n",
    "    quaternions = quaternions.reshape(batch_size*n_joints, 4)\n",
    "    quaternions = batch_quat_left_multiply(\n",
    "            batch_quat_inverse(rotation),\n",
    "            quaternions\n",
    "        )\n",
    "    quaternions = quaternions.reshape(batch_size, n_joints, 4)\n",
    "\n",
    "    # Use these quaternions in the forward kinematics with the Poppy skeleton\n",
    "    skeleton = forward_kinematics(\n",
    "            topology,\n",
    "            torch.zeros(batch_size, 3),\n",
    "            offsets,\n",
    "            quaternions\n",
    "        )[0]\n",
    "        \n",
    "    outputs= skeleton.clone()\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69536f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeleton topology\n",
    "topology = [0, 0, 1, 2, 0, 4, 5, 0, 7, 8, 9, 8, 11, 12, 8, 14, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = np.pi/4. \n",
    "\n",
    "rota_skeletons_B = change_frame(skeletons, 'general', alpha, topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a287448d",
   "metadata": {},
   "source": [
    "Plot the skeleton in the new reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20821d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "print(rota_skeletons_B.shape)\n",
    "t=10\n",
    "\n",
    "ax = pyplot_skeleton(topology, rota_skeletons_B[t], show=True, color='blue') #output by blazepose\n",
    "# ax=pyplot_skeleton(topology, rota_skeletons_B[t], ax=ax, show=True, color='red') #in the new reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7163237",
   "metadata": {},
   "source": [
    "Then, this function computes target XYZ positions for Poppy's kinematic chains' end effectors based on the skeleton obtained from blazepose. It proceeds as follows:\n",
    "- it estimates the source (i.e. video) bone lengths\n",
    "- it estimates the source (i.e. video) joint orientations using the \"find_quaternions\" util function\n",
    "- it reorients all the joint angles using as base orientation the pelvis -> chest axis\n",
    "- it computes the XYZ joint positions based on the found orientations and the poppy bone lengths\n",
    "\n",
    "A little trick is then applied, but could be removed. To decrease the depth of the movement estimated by blazepose, the y-axis values are divided by 10. To ensure that the target positions still correspond to achievable positions by the robot, we do another round of XYZ positions -> joint orientations -> XYZ positions.\n",
    "\n",
    "Finally, this function returns the joint XYZ positions only for kinematic chaine end effectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ac268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_from_skeleton(source_positions, topology):\n",
    "    # Works in batched\n",
    "    batch_size, n_joints, _ = source_positions.shape\n",
    "    \n",
    "    # Measure skeleton bone lengths\n",
    "    source_lengths = torch.Tensor(batch_size, n_joints)\n",
    "    for child, parent in enumerate(topology):\n",
    "        source_lengths[:, child] = torch.sqrt(\n",
    "            torch.sum(\n",
    "                (source_positions[:, child] - source_positions[:, parent])**2,\n",
    "                axis=-1\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    # Find the corresponding angles\n",
    "    source_offsets = torch.zeros(batch_size, n_joints, 3)\n",
    "    source_offsets[:, :, -1] = source_lengths\n",
    "    quaternions = find_quaternions(topology, source_offsets, source_positions)\n",
    "    \n",
    "    # Re-orient according to the pelvis->chest orientation\n",
    "    base_orientation = quaternions[:, 7:8].repeat(1, n_joints, 1).reshape(batch_size*n_joints, 4)\n",
    "    base_orientation += 1e-3 * torch.randn_like(base_orientation)\n",
    "    quaternions = quaternions.reshape(batch_size*n_joints, 4)\n",
    "    quaternions = batch_quat_left_multiply(\n",
    "        batch_quat_inverse(base_orientation),\n",
    "        quaternions\n",
    "    )\n",
    "    quaternions = quaternions.reshape(batch_size, n_joints, 4)\n",
    "    \n",
    "    # Use these quaternions in the forward kinematics with the Poppy skeleton\n",
    "    target_offsets = torch.zeros(batch_size, n_joints, 3)\n",
    "    target_offsets[:, :, -1] = poppy_lengths.unsqueeze(0).repeat(batch_size, 1)\n",
    "    target_positions = forward_kinematics(\n",
    "        topology,\n",
    "        torch.zeros(batch_size, 3),\n",
    "        target_offsets,\n",
    "        quaternions\n",
    "    )[0]\n",
    "\n",
    "    # Measure the hip orientation\n",
    "    alpha = np.arctan2(\n",
    "        target_positions[0, 1, 1] - target_positions[0, 0, 1],\n",
    "        target_positions[0, 1, 0] - target_positions[0, 0, 0]\n",
    "    )\n",
    "    \n",
    "    # Rotate by alpha around z\n",
    "    alpha = alpha\n",
    "    rotation = torch.Tensor([np.cos(alpha/2), 0, 0, np.sin(alpha/2)]).unsqueeze(0).repeat(batch_size*n_joints, 1)\n",
    "    quaternions = quaternions.reshape(batch_size*n_joints, 4)\n",
    "    quaternions = batch_quat_left_multiply(\n",
    "        batch_quat_inverse(rotation),\n",
    "        quaternions\n",
    "    )\n",
    "    quaternions = quaternions.reshape(batch_size, n_joints, 4)\n",
    "    \n",
    "    # Use these quaternions in the forward kinematics with the Poppy skeleton\n",
    "    target_positions = forward_kinematics(\n",
    "        topology,\n",
    "        torch.zeros(batch_size, 3),\n",
    "        target_offsets,\n",
    "        quaternions\n",
    "    )[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Return only target positions for the end-effector of the 6 kinematic chains:\n",
    "    # Chest, head, left hand, left elbow, left shoulder, right hand, right elbow\n",
    "    # end_effector_indices = [8, 10, 13, 12, 11, 16, 15]\n",
    "    end_effector_indices = [13, 16]\n",
    "    # end_effector_indices = [13, 12, 16, 15]\n",
    "\n",
    "    return target_positions[:, end_effector_indices], target_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppy_lengths = torch.Tensor([\n",
    "    0.0,\n",
    "    0.07,\n",
    "    0.18,\n",
    "    0.19,\n",
    "    0.07,\n",
    "    0.18,\n",
    "    0.19,\n",
    "    0.12,\n",
    "    0.08,\n",
    "    0.07,\n",
    "    0.05,\n",
    "    0.1, \n",
    "    0.15,\n",
    "    0.13,\n",
    "    0.1,\n",
    "    0.15,\n",
    "    0.13\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc05faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets, all_positions = targets_from_skeleton(skeletons, topology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676678b2",
   "metadata": {},
   "source": [
    "We can display the target skeleton with stars representing the end-effector target positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966744b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "t = t if t is not None else 0\n",
    "t = -100\n",
    "\n",
    "ax = pyplot_skeleton(topology, all_positions[t], show=False)\n",
    "ax.scatter(targets[t, :, 0], targets[t, :, 1], targets[t, :, 2], c='red', s=500, marker='*')\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "set_axes_equal(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8964897",
   "metadata": {},
   "source": [
    "For smoother movements, we compute a moving average of the target positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc72992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    repeat_shape = list(a.shape)\n",
    "    repeat_shape[1:] = [1 for _ in range(len(repeat_shape)-1)]\n",
    "    repeat_shape[0] = n//2\n",
    "    a = torch.cat([a[:1].repeat(*repeat_shape), a, a[-2:].repeat(*repeat_shape)])\n",
    "    ret = torch.cumsum(a, axis=0)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to have more keypoints for the inverse kinematics. It could be useful for fast movements.\n",
    "# With factor=1, it does nothing\n",
    "def interpolate_targets(targets, factor=1):\n",
    "    \n",
    "    length, joints, _ = targets.shape\n",
    "    \n",
    "    new_targets = torch.zeros((length-1) * factor + 1, joints, 3)\n",
    "    \n",
    "    for i in range(new_targets.shape[0]):\n",
    "            \n",
    "        target_id = float(i/factor)\n",
    "        before_id = int(np.floor(target_id))\n",
    "        after_id = int(np.floor(target_id + 1))\n",
    "        \n",
    "        before_coef = 1 - (target_id - before_id)\n",
    "        after_coef = 1 - (after_id - target_id)\n",
    "        \n",
    "        if after_id > length - 1:\n",
    "            after_id = length - 1\n",
    "        \n",
    "        new_targets[i] = before_coef * targets[before_id] + after_coef * targets[after_id]\n",
    "        \n",
    "    return new_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d093ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03d847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolated_targets = interpolate_targets(targets)\n",
    "smoothed_targets = moving_average(interpolated_targets, n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674c12fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(targets[:, :, 0])\n",
    "plt.suptitle('Raw Targets x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(targets[:, :, 1])\n",
    "plt.suptitle('Smoothed Targets x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d55b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(smoothed_targets[:, :, 0])\n",
    "plt.suptitle('Smoothed Targets y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13254637",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(smoothed_targets[:, :, 1])\n",
    "plt.suptitle('Smoothed Targets z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d2f1ef",
   "metadata": {},
   "source": [
    "These two functions perform inverse kinematics combining multiple kinematic chains at the same time. The upper_body_imitation uses torso, head, elbows and hands targets, while the arms_imitation only focuses on the two hands.\n",
    "\n",
    "If positions are provided, its uses it as initial positions, otherwise, it uses the current simulated robot configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7394e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_position(kinematic_chains, positions):\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for kc, joint_positions in zip(kinematic_chains, positions):       \n",
    "\n",
    "        for i, (motor, motor_position) in enumerate(zip(kc.motors, joint_positions)):\n",
    "                        \n",
    "            if motor.name not in enumerate(results.keys()) and kc.active_links_mask[i+1]:\n",
    "                results[motor.name] = [motor_position, 0.]\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d252a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_body_imitation(poppy, targets, positions=None):\n",
    "    \n",
    "    # Targets should be a tensor of shape (6, 3)\n",
    "    # In order: chest, head, r_hand, l_hand, l_elbow, r_elbow\n",
    "    kinematic_chains = [\n",
    "        #poppy.torso_chain,\n",
    "        #poppy.head_chain,\n",
    "        #poppy.l_shoulder_chain,\n",
    "        poppy.l_arm_chain,\n",
    "        #poppy.l_hand_chain,\n",
    "        poppy.r_arm_chain,\n",
    "    ]\n",
    "    \n",
    "    next_positions = []\n",
    "    \n",
    "    for i, kinematic_chain in enumerate(kinematic_chains):\n",
    "        \n",
    "        if positions is not None:\n",
    "            next_positions.append(ik(kinematic_chain, targets[i], positions[i]))\n",
    "        else:\n",
    "            next_positions.append(ik(kinematic_chain, targets[i]))\n",
    "\n",
    "    return next_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pypot.primitive.move import Move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daffdc91",
   "metadata": {},
   "source": [
    "This cell loops along the different frames of the input video and performs frame by frame imitation. It registers the found motor angles in a Move object that stores the whole Poppy movement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f05832",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppy_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7666c98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fps = 10\n",
    "\n",
    "for motor in poppy.motors:\n",
    "    motor.compliant = False\n",
    "\n",
    "# Upper body imitation seems to work better\n",
    "# Otherwise, the elbow might go to wrong positions that can block the motion later\n",
    "\n",
    "kinematic_chains = [\n",
    "    # poppy.torso_chain,\n",
    "    #poppy.head_chain,\n",
    "    #poppy.l_shoulder_chain,\n",
    "    poppy.l_arm_chain,\n",
    "    #poppy.l_elbow_chain,\n",
    "    # poppy.l_hand_chain,\n",
    "    poppy.r_arm_chain,\n",
    "    #poppy.r_elbow_chain,\n",
    "    # poppy.r_hand_chain,\n",
    "]\n",
    "\n",
    "#kinematic_chains = [\n",
    "#    poppy.l_arm_chain,\n",
    "#    poppy.r_arm_chain,\n",
    "#]\n",
    "\n",
    "positions = [k.joints_position for k in kinematic_chains]\n",
    "\n",
    "move = Move(freq=fps)\n",
    "\n",
    "for t in range(smoothed_targets.shape[0]):\n",
    "    time.sleep(1./fps)\n",
    "    #positions = upper_body_imitation(\n",
    "    #    poppy, \n",
    "    #    smoothed_targets[t],\n",
    "    #    # positions = positions\n",
    "    #)\n",
    "\n",
    "    positions = upper_body_imitation(\n",
    "        poppy,\n",
    "        smoothed_targets[t],\n",
    "    )\n",
    "        \n",
    "    move.add_position(\n",
    "        dict_from_position(kinematic_chains, positions), \n",
    "        float(t)/fps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59b81d",
   "metadata": {},
   "source": [
    "We can plot the evolution of the motor angles during the trajectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab7f2f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax = plt.axes()\n",
    "move.plot(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab09cb4f",
   "metadata": {},
   "source": [
    "save this movement to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb9cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "move.save(open('move.record', 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96e4833",
   "metadata": {},
   "source": [
    "## Play the saved move in the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppy_reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypot.primitive.move import MovePlayer, MoveRecorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bba2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothen_move(move):\n",
    "    \n",
    "    # Function to smoothen the Poppy movement\n",
    "    n = 10\n",
    "    \n",
    "    # Create a tensor from the dictionary\n",
    "    motors = move.positions()[0].keys()\n",
    "    move_tensor = torch.Tensor([\n",
    "        [move.positions()[t][motor]  for motor in motors] for t in move.positions().keys()\n",
    "    ])\n",
    "    \n",
    "    # Control the motor range\n",
    "    move_tensor = torch.minimum(move_tensor, torch.full(move_tensor.shape, 180.))\n",
    "    move_tensor = torch.maximum(move_tensor, torch.full(move_tensor.shape, -180.))\n",
    "    \n",
    "    # Moving average to smoothen the positions\n",
    "    move_tensor = moving_average(move_tensor, n=n)\n",
    "    \n",
    "    # Compute velocity as the (next position - previous positions) * fps / 2\n",
    "    move_tensor[1:-1, :, 1] = (move_tensor[2:, :, 0] - move_tensor[:-2, :, 0]) * 0.5 * move.framerate\n",
    "    \n",
    "    # Rebuild the dictionary from the tensor\n",
    "    new_move = Move(freq=move.framerate)\n",
    "        \n",
    "    for i in range(move_tensor.shape[0]):\n",
    "        dictionary = {}\n",
    "        for j, motor in enumerate(motors):\n",
    "            dictionary[motor] = move_tensor[i, j].tolist()\n",
    "        new_move.add_position(\n",
    "            dictionary,\n",
    "            float(i)/fps\n",
    "        )\n",
    "\n",
    "    return new_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_move = smoothen_move(move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a2c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MovePlayer(poppy, new_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abf8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2866c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "ax = plt.axes()\n",
    "new_move.plot(ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fb1bf",
   "metadata": {},
   "source": [
    "Finally, we save the move in a file, copy the file through ssh to the poppy robot, and send an API request to play the move. Note that the computer executing the notebook should be on the same network than poppy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b91484",
   "metadata": {},
   "source": [
    "# Your project\n",
    "\n",
    "Your task is to use the reinforcement learning and inverse reinforcement learning algorithms to learn how Poppy can imitate the movement, without using the inverse kinematics library.\n",
    "\n",
    "You can use stable baselines or imitation libraries. You can also use your own implementation of the RL or iRL algorithm.\n",
    "For using the libraries, it is recommended that you create your own gymnamsium environment (NB gymnasium is the new version of gym, it can be used in the previous code by replacing the import line by 'import gymnasium as gym').\n",
    "\n",
    "- You can refer to the documentation by gym on https://gymnasium.farama.org/tutorials/gymnasium_basics/environment_creation/ or https://www.gymlibrary.dev/content/environment_creation/. They propose a tutorial python notebook\n",
    "- You can also look at an example project with a similar robot, ErgoJr : https://github.com/fgolemo/gym-ergojr with the gym environment implementation : https://github.com/fgolemo/gym-ergojr/blob/master/gym_ergojr/envs/ergo_reacher_env.py\n",
    "\n",
    "The action is the joint positions given to each of the motors.\n",
    "The observation are the cartesian positions that can be accessed by commands like poppy.l_arm_chain.position.\n",
    "\n",
    "\n",
    "You also need to decide on the reward function to be used.\n",
    "\n",
    "Two interesting articles to get your inspiration can be read : \n",
    "\n",
    "- https://arxiv.org/abs/2209.05135\n",
    "- https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8956326&casa_token=10GKHz8KJR8AAAAA:OZNWV-X7RxXJqLlRNqMBEtBg7jbH4fyy8pjDiMf5cOT65USEECinEMOiEVj0VW5sUDETHjGVgA&tag=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32301a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gym stable-baselines3 torch\n",
    "# !pip install tqdm shimmy\n",
    "# !pip install tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a738b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "import os\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from pypot.creatures.ik import IKChain\n",
    "from pypot.primitive.move import Move\n",
    "from pypot.primitive.move import MovePlayer\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os\n",
    "# from PoppyEnv import PoppyEnv\n",
    "# from Poppy_Env import PoppyEnv\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "# from imitation.algorithms import bc\n",
    "import numpy as np\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from Poppy_Env_edouard import PoppyEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d73d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env = PoppyEnv()\n",
    "vec_env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913751ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Chemin vers les fichiers de données\n",
    "path = './resources/sample_poppy_skeletons/'\n",
    "file = 'Edouard_0_poppy_skeletons.pt'\n",
    "data_path = path + file\n",
    "\n",
    "# Charger les données\n",
    "poppy_skeletons = torch.load(data_path)\n",
    "\n",
    "# Vous devez déterminer comment ces données se mappent à vos observations et actions\n",
    "# Supposons que vos observations sont les positions des joints et les actions sont des différences entre les positions actuelles et les cibles\n",
    "observations = poppy_skeletons[:-1]  # toutes les frames sauf la dernière\n",
    "actions = poppy_skeletons[1:] - poppy_skeletons[:-1]  # différences entre les frames consécutives\n",
    "\n",
    "# Sauvegarder les données formatées pour l'apprentissage par imitation\n",
    "np.savez(path+'formatted_training_data.npz', obs=observations, acts=actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "data = load(path+'formatted_training_data.npz')\n",
    "lst = data.files\n",
    "# for item in lst:\n",
    "#     print(item)\n",
    "#     print(data[item])\n",
    "    \n",
    "print('observations: ', data['obs'].shape)\n",
    "print('actions: ', data['acts'].shape)\n",
    "\n",
    "for i in range(200):\n",
    "    print(data['acts'][i][16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afcb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d_hand_trajectory(targets, period=20, title='Targets -'):\n",
    "    \"\"\"\n",
    "    Plot 3D trajectories from a tensor and annotate specific points.\n",
    "    \n",
    "    Parameters:\n",
    "    - targets (torch.Tensor): A tensor with shape [N, 2, 3] where N is the number of time steps.\n",
    "    - period (int): The interval at which to place annotations and markers.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a 3D plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extracting the coordinates for both lines\n",
    "    x1, y1, z1 = targets[:, 0, 0], targets[:, 0, 1], targets[:, 0, 2]\n",
    "    x2, y2, z2 = targets[:, 1, 0], targets[:, 1, 1], targets[:, 1, 2]\n",
    "    \n",
    "    # Plotting line 1\n",
    "    ax.plot(x1.numpy(), y1.numpy(), z1.numpy(), label='Line 1')\n",
    "    \n",
    "    # Plotting line 2\n",
    "    ax.plot(x2.numpy(), y2.numpy(), z2.numpy(), label='Line 2')\n",
    "    \n",
    "    # Plot a dot every 'period' frames, annotate them, and adjust dot size and text position\n",
    "    for t in range(0, len(targets), period):\n",
    "        ax.scatter(x1[t].numpy(), y1[t].numpy(), z1[t].numpy(), color='black', s=10)  # Smaller dot size\n",
    "        ax.scatter(x2[t].numpy(), y2[t].numpy(), z2[t].numpy(), color='black', s=10)  # Smaller dot size\n",
    "        ax.text(x1[t].numpy() + 0.02, y1[t].numpy(), z1[t].numpy(), t, color='black', ha='left',fontsize=6)\n",
    "        ax.text(x2[t].numpy() + 0.02, y2[t].numpy(), z2[t].numpy(), t, color='black', ha='left',fontsize=6)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('X Coordinate')\n",
    "    ax.set_ylabel('Y Coordinate')\n",
    "    ax.set_zlabel('Z Coordinate')\n",
    "    ax.set_title(title + '3D Line Plot of Targets with Time Steps')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "plot_3d_hand_trajectory(torch.from_numpy(data['obs'][:121, [13, 16]]), period=10, title='Targets (all) -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba52f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a8f8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PoppyEnv()\n",
    "observation = env.reset()\n",
    "print(\"Observation:\", observation)\n",
    "print(\"Shape:\", observation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = DummyVecEnv([lambda: PoppyEnv()])\n",
    "observations = vec_env.reset()\n",
    "print(\"Vectorized Observations:\", observations)\n",
    "print(\"Shape:\", observations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3a22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gymnasium as gym\n",
    "\n",
    "from Poppy_Env_edouard import PoppyEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = PoppyEnv(observations, actions)\n",
    "env = PoppyEnv(gym.Env)\n",
    "\n",
    "# Envelopper l'environnement dans un DummyVecEnv\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "\n",
    "vec_env.reset()\n",
    "\n",
    "targets_obs, l_joints_obs, r_joints_obs = vec_env.get_attr(observation)\n",
    "print(targets_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bedb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour évaluer le modèle et obtenir la récompense moyenne\n",
    "def evaluate_model(model, env, num_episodes=10):\n",
    "    episode_rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            episode_reward += reward\n",
    "        episode_rewards.append(episode_reward)\n",
    "    return episode_rewards\n",
    "\n",
    "# Charger les données d'entraînement\n",
    "# training_data = np.load(path+'formatted_training_data.npz')\n",
    "# observations = training_data[\"obs\"]\n",
    "# actions = training_data[\"acts\"]\n",
    "\n",
    "# Créer une instance de l'environnement Poppy en passant les données d'entraînement\n",
    "\n",
    "\n",
    "# Créer le modèle SAC\n",
    "model = SAC(\"MlpPolicy\", vec_env, verbose=1)\n",
    "\n",
    "# Entraîner le modèle sur 10000 steps\n",
    "model.learn(total_timesteps=10)\n",
    "\n",
    "# Sauvegarder le modèle\n",
    "model.save(\"sac_poppy_model\")\n",
    "\n",
    "# Évaluer le modèle après l'entraînement\n",
    "mean_rewards = evaluate_model(model, vec_env)\n",
    "\n",
    "# Tracer l'évolution de la récompense moyenne\n",
    "plt.plot(mean_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Mean Reward')\n",
    "plt.title('Evolution of Mean Reward')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a01eb1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gymnasium as gym\n",
    "\n",
    "from Poppy_Env_edouard import PoppyEnv\n",
    "from ddpg_edouard import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e7e3246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am Poppy!\n"
     ]
    }
   ],
   "source": [
    "# Initialiser l'environnement et l'agent\n",
    "env = PoppyEnv()\n",
    "agent = DDPGAgent(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdf9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(env.action_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298e53b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coucou\n",
      "loading targets from :  anaele_bent_arms_0_poppy_skeletons.pt\n",
      "Initial state: [ 0.1140156  -0.14981436  0.04428952 -0.10221806 -0.17943247  0.07060341]\n",
      "joints_to_move :  [-0.05044762  0.03467317  0.05359936 -0.00675792 -0.02329176  0.03541482\n",
      " -0.078188    0.04502027  0.06039118  0.03796803 -0.05263273 -0.00893448\n",
      " -0.00932623]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050447617 11.216428745537996\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.053599358 7.947964668273926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.023291755 87.9037420079112\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.03541482 -67.63046243228018\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.078188 9.135899841785431\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.045020275 7.4761151149868965\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.008934484 89.1958964522928\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.009326225 -73.78235595766455\n",
      "reward :  0.0016470327663351738\n",
      "current step :  1\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05145824  0.0457729   0.06238474 -0.03997684 -0.07483526  0.05835958\n",
      " -0.10486481  0.03544097  0.09048061  0.05199485 -0.02473543 -0.01318282\n",
      " -0.04458081]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.051458243 11.140631753951311\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.062384736 8.431160468608141\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07483526 83.26482631266117\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058359582 -64.47555747814476\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.104864806 7.135139554738998\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.035440966 6.949253156781197\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.013182817 88.81354646757245\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044580806 -78.6298608314246\n",
      "reward :  0.0017584691622053736\n",
      "current step :  2\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05096253  0.04584041  0.06153819 -0.03954046 -0.07469276  0.05808207\n",
      " -0.10308097  0.03481983  0.09057102  0.05301315 -0.02580465 -0.01263722\n",
      " -0.04435497]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.05096253 11.177810244262218\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06153819 8.384600430727005\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.074692756 83.27765196561813\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.05808207 -64.51371534727514\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.103080966 7.268927581608295\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.034819826 6.915090456604958\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012637218 88.86265033856034\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.04435497 -78.59880858100951\n",
      "reward :  0.0017281051793647062\n",
      "current step :  3\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093193  0.04587582  0.06152817 -0.03950111 -0.07471887  0.05811403\n",
      " -0.10297658  0.03479615  0.09052169  0.05309663 -0.02587506 -0.01258841\n",
      " -0.04433337]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050931934 11.180104929953814\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.061528172 8.384049478918314\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07471887 83.27530167996883\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114026 -64.50932146050036\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.102976575 7.276756837964058\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03479615 6.913788169622421\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012588413 88.86704279109836\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.04433337 -78.5958381742239\n",
      "reward :  0.0022394320421578523\n",
      "current step :  4\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05092203  0.04588387  0.06153617 -0.03947675 -0.07476191  0.05811379\n",
      " -0.1029648   0.0348063   0.09050968  0.05308115 -0.02588124 -0.01260204\n",
      " -0.0443561 ]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.05092203 11.180847845971584\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06153617 8.384489379823208\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476191 83.27142789959908\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058113795 -64.50935321860015\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.102964796 7.277640290558338\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.0348063 6.914346497505903\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602042 88.86581618338823\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044356097 -78.59896327368915\n",
      "reward :  0.003506015932982383\n",
      "current step :  5\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05092607  0.04588406  0.06153902 -0.03947452 -0.07476218  0.05811405\n",
      " -0.10296566  0.03480924  0.09050795  0.0530784  -0.02587949 -0.01260233\n",
      " -0.04435237]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050926067 11.18054497987032\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06153902 8.384646121412516\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476218 83.27140375971794\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114048 -64.50931838713586\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296566 7.277575470507145\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.034809243 6.914508361369371\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.0126023255 88.86579070240259\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044352375 -78.59845155850053\n",
      "reward :  0.0033011764417625977\n",
      "current step :  6\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.002719035146504592\n",
      "current step :  7\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.0025781140447158238\n",
      "current step :  8\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.002505968026118996\n",
      "current step :  9\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.002892348575225795\n",
      "current step :  10\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.00313063011854784\n",
      "current step :  11\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.003029399121604702\n",
      "current step :  12\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.0034311656542196727\n",
      "current step :  13\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.003838400516051306\n",
      "current step :  14\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.003698563346922092\n",
      "current step :  15\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n",
      "reward :  0.004685051410560835\n",
      "current step :  16\n",
      "episode :  0\n",
      "joints_to_move :  [-0.05093006  0.04588423  0.06154182 -0.03947233 -0.07476244  0.0581143\n",
      " -0.10296657  0.03481218  0.09050623  0.05307567 -0.02587772 -0.01260259\n",
      " -0.04434871]\n",
      "l_elbow_y -60.0 90.0\n",
      "l_elbow_y -0.050930064 11.18024518713355\n",
      "r_arm_z -50.0 60.0\n",
      "r_arm_z 0.06154182 8.38480019941926\n",
      "r_shoulder_x 0.0 180.0\n",
      "r_shoulder_x -0.07476244 83.27138029038906\n",
      "r_shoulder_y -210.0 65.0\n",
      "r_shoulder_y 0.058114298 -64.50928406789899\n",
      "r_elbow_y -60.0 90.0\n",
      "r_elbow_y -0.10296657 7.277507297694683\n",
      "l_arm_z -50.0 60.0\n",
      "l_arm_z 0.03481218 6.914669815450907\n",
      "l_shoulder_x 0.0 180.0\n",
      "l_shoulder_x -0.012602594 88.86576656252146\n",
      "l_shoulder_y -210.0 65.0\n",
      "l_shoulder_y -0.044348706 -78.59794701449573\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Routine d'entraînement\n",
    "num_episodes = 3\n",
    "# for episode in range(num_episodes):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     total_reward = 0\n",
    "#     while not done:\n",
    "#         action = agent.act(state)\n",
    "#         next_state, reward, done, _ = env.step(action)\n",
    "#         agent.step(state, action, reward, next_state, done)\n",
    "#         state = next_state\n",
    "#         total_reward += reward\n",
    "#     print(f'Episode {episode + 1}, Total Reward: {total_reward}')\n",
    "    \n",
    "rew = []\n",
    "for episode in range(num_episodes):\n",
    "    state, info = env.reset()  # Assurez-vous que reset retourne également 'info'\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        assert state.shape == (6,), f\"Invalid state shape: {state.shape}\"\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    rew.append(total_reward)\n",
    "    print(f'Episode {episode + 1}, Total Reward: {total_reward}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90227845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Après l'entraînement\n",
    "torch.save(agent.actor.state_dict(), 'actor_model.pth')\n",
    "\n",
    "# Avant la démonstration\n",
    "agent.actor.load_state_dict(torch.load('actor_model.pth'))\n",
    "agent.actor.eval()  # Passer le modèle en mode évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5638d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, info = env.reset()\n",
    "env.get_target()\n",
    "print(np.r_[env.targets[0][13], env.targets[0][16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_reward = 0\n",
    "while not done:\n",
    "    action = agent.act(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "print(\"Total Reward during demonstration:\", total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ed6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from utils.skeleton import *\n",
    "from utils.quaternion import *\n",
    "from utils.blazepose import blazepose_skeletons\n",
    "\n",
    "from pypot.creatures import PoppyTorso\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "import gymnasium as gym\n",
    "\n",
    "from Poppy_Env_edouard import PoppyEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19ef6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env.close()\n",
    "from pypot import vrep\n",
    "vrep.close_all_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the environment\n",
    "# env = make_vec_env(lambda: PoppyEnv(), n_envs=1)\n",
    "\n",
    "# # Initialize the agent\n",
    "# model = SAC(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./sac_poppy_tensorboard/\")\n",
    "\n",
    "# # Train the agent\n",
    "# total_timesteps = 3  # Set this to a higher number for better results\n",
    "# model.learn(total_timesteps=total_timesteps)\n",
    "\n",
    "# # Save the model\n",
    "# model.save(\"sac_poppy_model\")\n",
    "\n",
    "# # Optionally evaluate the policy\n",
    "# mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)\n",
    "# print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n",
    "\n",
    "# # Close the environment\n",
    "# env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243295ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
